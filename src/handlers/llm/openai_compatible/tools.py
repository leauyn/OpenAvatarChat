import requests
import json
import redis
import re
import yaml
import os
from loguru import logger
from openai import OpenAI

# å…¨å±€ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
_survey_data_cache = {}
_user_info_cache = {}
_simplify_cache = {}  # LLMç²¾ç®€ç»“æœç¼“å­˜

# Redis è¿æ¥é…ç½®
REDIS_HOST = 'localhost'
REDIS_PORT = 6779
REDIS_DB = 0

# LLMç²¾ç®€åŠŸèƒ½ç‹¬ç«‹é…ç½®
SIMPLIFY_LLM_CONFIG = {
    "api_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "api_key": os.getenv("DASHSCOPE_API_KEY"),
    "model": "qwen-plus",
    "temperature": 0.1,
    "max_tokens": 2000
}

# å…¨å±€LLMå®¢æˆ·ç«¯å®ä¾‹
_simplify_llm_client = None

def get_default_llm_config():
    """è·å–LLMç²¾ç®€åŠŸèƒ½çš„é»˜è®¤é…ç½®"""
    return {
        "api_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "model": "qwen-flash",
        "temperature": 0.1,
        "max_tokens": 2000,
        "enable_llm_simplify": True,
        "fallback_to_regex": True,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†æµ‹è¯„æŠ¥å‘Šå¤„ç†åŠ©æ‰‹ï¼Œæ“…é•¿ç²¾ç®€å’Œæå–æ ¸å¿ƒä¿¡æ¯ã€‚",
        "user_prompt_template": ""
    }

def load_simplify_llm_config():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½LLMç²¾ç®€åŠŸèƒ½é…ç½®"""
    global SIMPLIFY_LLM_CONFIG
    
    config_path = os.path.join(os.path.dirname(__file__), '../../../config/simplify_llm_config.yaml')
    
    # è·å–é»˜è®¤é…ç½®
    default_config = get_default_llm_config()
    
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                file_config = yaml.safe_load(f)
            
            # ä½¿ç”¨é»˜è®¤é…ç½®ä½œä¸ºåŸºç¡€ï¼Œæ–‡ä»¶é…ç½®è¦†ç›–é»˜è®¤å€¼
            SIMPLIFY_LLM_CONFIG = {**default_config, **file_config}
            
            logger.info(f"âœ… LLMç²¾ç®€é…ç½®å·²ä»æ–‡ä»¶åŠ è½½: {config_path}")
            return True
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            SIMPLIFY_LLM_CONFIG = default_config
            logger.warning(f"âš ï¸ LLMç²¾ç®€é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return False
    except Exception as e:
        logger.error(f"âŒ åŠ è½½LLMç²¾ç®€é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        SIMPLIFY_LLM_CONFIG = default_config
        return False

def get_redis_connection():
    """è·å– Redis è¿æ¥ï¼Œç¡®ä¿ä»¥æ–‡æœ¬æ ¼å¼å­˜å‚¨"""
    try:
        r = redis.Redis(
            host=REDIS_HOST, 
            port=REDIS_PORT, 
            db=REDIS_DB, 
            decode_responses=True,  # ç¡®ä¿è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—èŠ‚
            encoding='utf-8'        # æ˜ç¡®æŒ‡å®šç¼–ç 
        )
        # æµ‹è¯•è¿æ¥
        r.ping()
        return r
    except Exception as e:
        logger.error(f"Redis è¿æ¥å¤±è´¥: {e}")
        return None


def get_simplify_llm_client():
    """è·å–LLMç²¾ç®€åŠŸèƒ½çš„å®¢æˆ·ç«¯ï¼Œé¿å…å¤šæ¬¡åˆå§‹åŒ–"""
    global _simplify_llm_client
    
    if _simplify_llm_client is None:
        try:
            # æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆ
            api_key = SIMPLIFY_LLM_CONFIG.get("api_key")
            if not api_key or api_key == "sk-your-simplify-api-key":
                logger.warning("âš ï¸ LLMç²¾ç®€API Keyæœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return None
            
            _simplify_llm_client = OpenAI(
                api_key=api_key,
                base_url=SIMPLIFY_LLM_CONFIG["api_url"]
            )
            logger.info(f"âœ… LLMç²¾ç®€å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {SIMPLIFY_LLM_CONFIG['model']}")
        except Exception as e:
            logger.error(f"âŒ LLMç²¾ç®€å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return None
    else:
        logger.debug("ğŸ”„ ä½¿ç”¨å·²åˆå§‹åŒ–çš„LLMç²¾ç®€å®¢æˆ·ç«¯")
    
    return _simplify_llm_client


def update_simplify_llm_config(**kwargs):
    """æ›´æ–°LLMç²¾ç®€åŠŸèƒ½é…ç½®"""
    global _simplify_llm_client
    
    # æ›´æ–°é…ç½®
    for key, value in kwargs.items():
        if key in SIMPLIFY_LLM_CONFIG:
            SIMPLIFY_LLM_CONFIG[key] = value
    
    # é‡ç½®å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
    _simplify_llm_client = None
    
    logger.info(f"âœ… LLMç²¾ç®€é…ç½®å·²æ›´æ–°: {SIMPLIFY_LLM_CONFIG}")
    return SIMPLIFY_LLM_CONFIG

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_user_info",
            "description": "å½“ä½ æƒ³æŸ¥è¯¢æŒ‡å®šç”¨æˆ·çš„ä¸ªäººä¿¡æ¯æ—¶éå¸¸æœ‰ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "åŸºæœ¬ä¿¡æ¯ï¼Œæ¯”å¦‚å§“åã€æ€§åˆ«ã€å¹´é¾„ã€åœ°å€ã€å­¦æ ¡ç­‰ã€‚",
                    }
                },
                "required": ["user_id"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_user_survey_data",
            "description": "å½“ä½ æƒ³æŸ¥è¯¢æŒ‡å®šç”¨æˆ·çš„æµ‹è¯„æ•°æ®ã€æŠ¥å‘Šã€æˆ–ç»“æœæ—¶éå¸¸æœ‰ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "æµ‹è¯„æ•°æ®ï¼Œæ¯”å¦‚é‡ç‚¹å…³æ³¨ã€ä¸€èˆ¬å…³æ³¨ã€å¥åº·ç­‰ã€‚",
                    }
                },
                "required": ["user_id"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "query_knowledge_base",
            "description": "å½“ç”¨æˆ·è¯¢é—®ä»»ä½•å¿ƒç†å¥åº·ã€å¿ƒç†ç†è®ºã€å¿ƒç†å’¨è¯¢ã€å¿ƒç†ç–¾ç—…ã€å¿ƒç†ç—‡çŠ¶ã€å¿ƒç†æµ‹è¯„ã€å¿ƒç†æ²»ç–—æ–¹æ³•ã€å¿ƒç†å¹²é¢„ç­‰ç›¸å…³é—®é¢˜æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ­¤å·¥å…·æŸ¥è¯¢ä¸“ä¸šçŸ¥è¯†åº“è·å–æƒå¨ç­”æ¡ˆã€‚è¿™æ˜¯è·å–ä¸“ä¸šå¿ƒç†çŸ¥è¯†çš„å”¯ä¸€é€”å¾„ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "è¦æŸ¥è¯¢çš„å¿ƒç†å¥åº·ç›¸å…³é—®é¢˜ï¼Œå¦‚å¿ƒç†ç†è®ºã€å’¨è¯¢æ–¹æ³•ã€æµ‹è¯„çŸ¥è¯†ç­‰ã€‚",
                    }
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_guidance_plan",
            "description": "æ ¹æ®æµ‹è¯„ç»“æœçš„codeå€¼æŸ¥è¯¢å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚å½“ç”¨æˆ·éœ€è¦è·å–å…·ä½“çš„å¿ƒç†æŒ‡å¯¼å»ºè®®æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "æµ‹è¯„ç»“æœçš„codeå€¼ï¼Œå¦‚'1-5-C'ï¼Œç”¨äºæŸ¥è¯¢å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚",
                    }
                },
                "required": ["code"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_guidance_by_dimension",
            "description": "æ ¹æ®æµ‹è¯„ç»´åº¦åç§°è·å–å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚å½“ç”¨æˆ·è¯¢é—®å…·ä½“æµ‹è¯„ç»´åº¦çš„è§£å†³æ–¹æ¡ˆæˆ–æŒ‡å¯¼æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ç”¨æˆ·IDï¼Œç”¨äºè·å–è¯¥ç”¨æˆ·çš„æµ‹è¯„ç»“æœã€‚",
                    },
                    "dimension_name": {
                        "type": "string",
                        "description": "æµ‹è¯„ç»´åº¦åç§°ï¼Œå¦‚'å¸ˆç”Ÿå…³ç³»'ã€'åŒä¼´å…³ç³»'ã€'å­¦ä¹ ç„¦è™‘'ã€'æŠ‘éƒ'ã€'è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ'ç­‰ã€‚",
                    }
                },
                "required": ["user_id", "dimension_name"],
            },
        },
    },
]

def parse_survey_data(data_list: list) -> str:
    """
    è§£ææµ‹è¯„æ•°æ®ï¼ŒæŒ‰ç¾¤ä½“åˆ†ç±»ç»„ç»‡æ•°æ®
    è¾“å‡ºæ ¼å¼ï¼šé‡ç‚¹å…³æ³¨: é¡¹ç›®1, é¡¹ç›®2; ä¸€èˆ¬å…³æ³¨: é¡¹ç›®3, é¡¹ç›®4; å¥åº·: é¡¹ç›®5, é¡¹ç›®6
    è‡ªåŠ¨å»é‡ï¼Œæ¯ä¸ªæµ‹è¯„é¡¹ç›®åªä¿ç•™ä¸€ä¸ªç»“æœ
    """
    # æŒ‰ç¾¤ä½“åˆ†ç±»å­˜å‚¨æ•°æ®ï¼Œä½¿ç”¨é›†åˆå»é‡
    group_categories = {
        "é‡ç‚¹å…³æ³¨": set(),
        "ä¸€èˆ¬å…³æ³¨": set(),
        "å¥åº·": set()
    }
    
    for item in data_list:
        if "name" not in item or "value" not in item:
            continue
            
        name = item["name"]
        value = item["value"]
        
        # æå–ç¾¤ä½“ä¿¡æ¯ï¼šæŸ¥æ‰¾ "A." å’Œ "B." ä¹‹é—´çš„ç¾¤ä½“ä¿¡æ¯
        import re
        pattern = r'A\.\s*æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œè¯¥å­¦ç”Ÿ.*?æƒ…å†µï¼Œå¤„äº(.*?)ç¾¤ä½“'
        match = re.search(pattern, value)
        
        if match:
            group_info = match.group(1).strip()
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            pattern2 = r'å¤„äº(.*?)ç¾¤ä½“'
            match2 = re.search(pattern2, value)
            if match2:
                group_info = match2.group(1).strip()
            else:
                # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè·³è¿‡è¯¥é¡¹ç›®
                continue
        
        # æ ¹æ®ç¾¤ä½“ä¿¡æ¯åˆ†ç±»
        if group_info == "é‡ç‚¹å…³æ³¨":
            group_categories["é‡ç‚¹å…³æ³¨"].add(name)
        elif group_info == "ä¸€èˆ¬å…³æ³¨":
            group_categories["ä¸€èˆ¬å…³æ³¨"].add(name)
        elif group_info == "å¥åº·":
            group_categories["å¥åº·"].add(name)
    
    # æ„å»ºè¾“å‡ºå­—ç¬¦ä¸²
    result_lines = []
    for category, items in group_categories.items():
        if items:  # åªæ·»åŠ éç©ºçš„åˆ†ç±»
            # å°†é›†åˆè½¬æ¢ä¸ºæ’åºçš„åˆ—è¡¨ï¼Œç¡®ä¿è¾“å‡ºé¡ºåºä¸€è‡´
            sorted_items = sorted(list(items))
            result_lines.append(f"{category}: {', '.join(sorted_items)}")
    
    return "\n".join(result_lines)


def parse_user_info(user_data: dict) -> str:
    """
    è§£æç”¨æˆ·ä¿¡æ¯ï¼Œæå–æŒ‡å®šå­—æ®µ
    åŒ…å«ï¼šå§“å(name), å¹´çº§(nj)ï¼Œç­çº§(bj)ï¼Œåœ°å€(addressCode)ï¼Œæ€§åˆ«ï¼ˆsex)ï¼Œ å­¦æ ¡åç§°ï¼ˆschoolNameï¼‰
    å¦‚ä¸º null åˆ™ä¸è§£æ
    """
    user_info_lines = []
    
    # å®šä¹‰å­—æ®µæ˜ å°„
    field_mapping = {
        'name': 'å§“å',
        'nj': 'å¹´çº§', 
        'bj': 'ç­çº§',
        'addressCode': 'åœ°å€',
        'sex': 'æ€§åˆ«',
        'schoolName': 'å­¦æ ¡åç§°'
    }
    
    # æ€§åˆ«æ˜ å°„
    sex_mapping = {'1': 'ç”·', '2': 'å¥³', '0': 'æœªçŸ¥'}
    
    for field, display_name in field_mapping.items():
        if field in user_data and user_data[field] is not None:
            value = user_data[field]
            # ç‰¹æ®Šå¤„ç†æ€§åˆ«å­—æ®µ
            if field == 'sex' and value in sex_mapping:
                value = sex_mapping[value]
            user_info_lines.append(f"{display_name}: {value}")
    
    return "\n".join(user_info_lines)


def get_user_info(user_id: str) -> str:
    """
    è·å–ç”¨æˆ·ä¿¡æ¯å¹¶è¿”å›è§£æç»“æœ
    ä½¿ç”¨ Redis ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
    """
    # é»˜è®¤API URL
    api_url = "https://www.zhgk-mind.com/api/dwsurvey/anon/response/userInfo.do"
    
    # Redis ç¼“å­˜ key æ ¼å¼: userid:user_info
    redis_key = f"{user_id}:user_info"
    
    # å°è¯•ä» Redis è·å–ç¼“å­˜
    redis_conn = get_redis_connection()
    if redis_conn:
        try:
            cached_data = redis_conn.get(redis_key)
            if cached_data:
                logger.debug(f"Using Redis cached user info for user {user_id}")
                return cached_data
        except Exception as e:
            logger.warning(f"Redis è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
    
    # å¦‚æœ Redis ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜
    cache_key = f"{user_id}_{api_url}"
    if cache_key in _user_info_cache:
        logger.debug(f"Using memory cached user info for user {user_id}")
        return _user_info_cache[cache_key]
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
            'Referer': 'https://www.zhgk-mind.com/'
        }
        
        response = requests.get(f"{api_url}?userId={user_id}", headers=headers, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get("resultCode") == 200 and "data" in result:
            user_data = result["data"]
            parsed_info = parse_user_info(user_data)
            
            # ä¼˜å…ˆå­˜å‚¨åˆ° Redis
            if redis_conn:
                try:
                    redis_conn.set(redis_key, parsed_info, ex=604800)  # è®¾ç½®1å‘¨è¿‡æœŸæ—¶é—´
                    logger.info(f"Cached user info to Redis for user {user_id} (expires in 1 week)")
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
                    # å›é€€åˆ°å†…å­˜ç¼“å­˜
                    _user_info_cache[cache_key] = parsed_info
                    logger.info(f"Cached user info to memory for user {user_id}")
            else:
                # Redis ä¸å¯ç”¨æ—¶ä½¿ç”¨å†…å­˜ç¼“å­˜
                _user_info_cache[cache_key] = parsed_info
                logger.info(f"Cached user info to memory for user {user_id}")
            
            return parsed_info
        else:
            logger.warning(f"Failed to get user info: {result.get('resultMsg', 'Unknown error')}")
            return ""
    except Exception as e:
        logger.error(f"Error fetching user info: {e}")
        return ""


def get_user_survey_data(user_id: str) -> str:
    """
    è·å–ç”¨æˆ·æµ‹è¯„æ•°æ®å¹¶è¿”å›è¯¦ç»†è§£æç»“æœ
    ä½¿ç”¨ get_survey_detail å‡½æ•°è·å–è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    æ”¯æŒLLMç²¾ç®€å†…å®¹
    """
    # ç›´æ¥è°ƒç”¨ get_survey_detail å‡½æ•°è·å–è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    return get_survey_detail(user_id)


def query_knowledge_base(query: str, rag_api_url: str = None, rag_api_key: str = None, rag_model: str = None) -> str:
    """
    æŸ¥è¯¢çŸ¥è¯†åº“è·å–ä¸“ä¸šå¿ƒç†çŸ¥è¯†ç­”æ¡ˆ
    è¿”å›å®Œæ•´çš„å›ç­”å†…å®¹ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    # é»˜è®¤RAGé…ç½®
    default_rag_api_url = "https://ragflow.thinnovate.com/api/v1/chats_openai/9a15923a991b11f088f40242ac170006/chat/completions"
    default_rag_api_key = "ragflow-I5ZWIyNDk0OTg3MDExZjBiZWNlMDI0Mm"
    default_rag_model = "model"
    
    # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤å€¼
    api_url = rag_api_url or default_rag_api_url
    api_key = rag_api_key or default_rag_api_key
    model = rag_model or default_rag_model
    
    logger.info(f"ğŸ§  RAGå·¥å…·è°ƒç”¨å¼€å§‹")
    logger.info(f"ğŸ“ æŸ¥è¯¢é—®é¢˜: {query}")
    logger.info(f"ğŸ”— API URL: {api_url}")
    logger.info(f"ğŸ”‘ API Key: {api_key[:20]}...")
    logger.info(f"ğŸ¤– Model: {model}")
    
    try:
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        
        data = {
            "model": model,
            "messages": [{"role": "user", "content": query}],
            "stream": True
        }
        
        logger.info(f"æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œé—®é¢˜: {query[:50]}...")
        response = requests.post(api_url, headers=headers, json=data, timeout=30, stream=True)
        response.raise_for_status()
        
        full_response = ""
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data:'):
                    try:
                        json_data = json.loads(line[5:])  # å»æ‰ 'data:' å‰ç¼€
                        if (json_data.get('choices') and 
                            len(json_data['choices']) > 0 and 
                            json_data['choices'][0].get('delta', {}).get('content') is not None):
                            content = json_data['choices'][0]['delta']['content']
                            if content:  # ç¡®ä¿contentä¸ä¸ºç©ºå­—ç¬¦ä¸²
                                full_response += content
                    except json.JSONDecodeError as e:
                        logger.debug(f"JSONè§£æé”™è¯¯: {e}, åŸå§‹æ•°æ®: {line}")
                        continue
        
        # æ£€æŸ¥æ˜¯å¦è¿”å›äº†"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°æ‚¨è¦çš„ç­”æ¡ˆ"
        if "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°æ‚¨è¦çš„ç­”æ¡ˆ" in full_response:
            logger.warning("âš ï¸ çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ç­”æ¡ˆ")
            return ""
        
        logger.info(f"âœ… çŸ¥è¯†åº“æŸ¥è¯¢æˆåŠŸï¼Œè¿”å›ç­”æ¡ˆé•¿åº¦: {len(full_response)} å­—ç¬¦")
        if full_response:
            logger.info(f"ğŸ“„ çŸ¥è¯†åº“è¿”å›å†…å®¹é¢„è§ˆ: {full_response[:200]}...")
        return full_response
        
    except Exception as e:
        logger.error(f"âŒ çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {e}")
        return ""


def get_guidance_plan(code: str) -> str:
    """
    æ ¹æ®æµ‹è¯„ç»“æœçš„codeå€¼æŸ¥è¯¢å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆ
    ä½¿ç”¨ Redis ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
    """
    # é»˜è®¤API URL
    api_url = "https://www.zhgk-mind.com/api/dwsurvey/anon/response/getBaseMindResult.do"
    
    # Redis ç¼“å­˜ key æ ¼å¼: code:guidance
    redis_key = f"{code}:guidance"
    
    # å°è¯•ä» Redis è·å–ç¼“å­˜
    redis_conn = get_redis_connection()
    if redis_conn:
        try:
            cached_data = redis_conn.get(redis_key)
            if cached_data:
                logger.debug(f"Using Redis cached guidance plan for code {code}")
                return cached_data
        except Exception as e:
            logger.warning(f"Redis è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
    
    # å¦‚æœ Redis ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜
    cache_key = f"{code}_guidance"
    if cache_key in _user_info_cache:  # å¤ç”¨ç°æœ‰çš„ç¼“å­˜å­—å…¸
        logger.debug(f"Using memory cached guidance plan for code {code}")
        return _user_info_cache[cache_key]
    
    try:
        headers = {'content-type': 'application/json'}
        data = {"code": code}
        
        logger.info(f"æŸ¥è¯¢æŒ‡å¯¼æ–¹æ¡ˆï¼Œcode: {code}")
        response = requests.post(api_url, headers=headers, json=data, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get("resultCode") == 200 and "data" in result and result["data"]:
            guidance_data = result["data"][0]  # å–ç¬¬ä¸€ä¸ªç»“æœ
            guidance_text = guidance_data.get("value", "")
            
            # æ¸…ç†æ–‡æœ¬ä¸­çš„ \r\n æ¢è¡Œç¬¦ï¼Œæ›¿æ¢ä¸º \n
            guidance_text = guidance_text.replace('\r\n', '\n')
            
            # ä¼˜å…ˆå­˜å‚¨åˆ° Redis
            if redis_conn:
                try:
                    redis_conn.set(redis_key, guidance_text, ex=604800)  # è®¾ç½®1å‘¨è¿‡æœŸæ—¶é—´
                    logger.info(f"Cached guidance plan to Redis for code {code} (expires in 1 week)")
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
                    # å›é€€åˆ°å†…å­˜ç¼“å­˜
                    _user_info_cache[cache_key] = guidance_text
                    logger.info(f"Cached guidance plan to memory for code {code}")
            else:
                # Redis ä¸å¯ç”¨æ—¶ä½¿ç”¨å†…å­˜ç¼“å­˜
                _user_info_cache[cache_key] = guidance_text
                logger.info(f"Cached guidance plan to memory for code {code}")
            
            logger.info(f"âœ… æŒ‡å¯¼æ–¹æ¡ˆæŸ¥è¯¢æˆåŠŸï¼Œcode: {code}, å†…å®¹é•¿åº¦: {len(guidance_text)} å­—ç¬¦")
            return guidance_text
        else:
            logger.warning(f"Failed to get guidance plan for code {code}: {result.get('resultMsg', 'Unknown error')}")
            return ""
    except Exception as e:
        logger.error(f"Error fetching guidance plan for code {code}: {e}")
        return ""


def get_survey_detail(user_id: str) -> str:
    """
    è·å–ç”¨æˆ·è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    ä»å“åº”åˆ—è¡¨ä¸­æŠ½å–å„ä¸ªæµ‹è¯„ç»´åº¦ä¸­çš„ nameï¼ˆç»´åº¦åç§°ï¼‰ã€resulteï¼ˆæµ‹è¯„ç»“æœ codeï¼‰ä¸ valueå€¼ï¼ˆè¯¦ç»†æµ‹è¯„ä¿¡æ¯ï¼‰
    ä½¿ç”¨ Redis ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
    æ”¯æŒLLMç²¾ç®€å†…å®¹
    """
    # é»˜è®¤API URL
    api_url = "https://www.zhgk-mind.com/api/dwsurvey/anon/response/getUserResultInfo.do"
    
    # Redis ç¼“å­˜ key æ ¼å¼: userid:survey_detail
    redis_key = f"{user_id}:survey_detail"
    
    # å°è¯•ä» Redis è·å–ç¼“å­˜
    redis_conn = get_redis_connection()
    if redis_conn:
        try:
            cached_data = redis_conn.get(redis_key)
            if cached_data:
                logger.debug(f"Using Redis cached survey detail for user {user_id}")
                return cached_data
        except Exception as e:
            logger.warning(f"Redis è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
    
    # å¦‚æœ Redis ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜
    cache_key = f"{user_id}_survey_detail"
    if cache_key in _user_info_cache:  # å¤ç”¨ç°æœ‰çš„ç¼“å­˜å­—å…¸
        logger.debug(f"Using memory cached survey detail for user {user_id}")
        return _user_info_cache[cache_key]
    
    try:
        headers = {'content-type': 'application/json'}
        data = {"userId": user_id}
        
        logger.info(f"æŸ¥è¯¢è¯¦ç»†æµ‹è¯„æŠ¥å‘Šï¼Œuser_id: {user_id}")
        response = requests.post(api_url, headers=headers, json=data, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get("resultCode") == 200 and "data" in result:
            data_list = result["data"]
            parsed_detail = parse_survey_detail(data_list)
            
            # ä¼˜å…ˆå­˜å‚¨åˆ° Redis
            if redis_conn:
                try:
                    redis_conn.set(redis_key, parsed_detail, ex=604800)  # è®¾ç½®1å‘¨è¿‡æœŸæ—¶é—´
                    logger.info(f"Cached survey detail to Redis for user {user_id} (expires in 1 week)")
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
                    # å›é€€åˆ°å†…å­˜ç¼“å­˜
                    _user_info_cache[cache_key] = parsed_detail
                    logger.info(f"Cached survey detail to memory for user {user_id}")
            else:
                # Redis ä¸å¯ç”¨æ—¶ä½¿ç”¨å†…å­˜ç¼“å­˜
                _user_info_cache[cache_key] = parsed_detail
                logger.info(f"Cached survey detail to memory for user {user_id}")
            
            logger.info(f"âœ… è¯¦ç»†æµ‹è¯„æŠ¥å‘ŠæŸ¥è¯¢æˆåŠŸï¼Œuser_id: {user_id}, å†…å®¹é•¿åº¦: {len(parsed_detail)} å­—ç¬¦")
            return parsed_detail
        else:
            logger.warning(f"Failed to get survey detail for user {user_id}: {result.get('resultMsg', 'Unknown error')}")
            return ""
    except Exception as e:
        logger.error(f"Error fetching survey detail for user {user_id}: {e}")
        return ""


def parse_survey_detail(data_list: list) -> str:
    """
    è§£æè¯¦ç»†æµ‹è¯„æ•°æ®ï¼Œæå–å„ä¸ªç»´åº¦çš„ä¿¡æ¯
    è¾“å‡ºæ ¼å¼ï¼šç»´åº¦åç§°: æµ‹è¯„ç»“æœcode - è¯¦ç»†æµ‹è¯„ä¿¡æ¯
    ä½¿ç”¨æ‰¹é‡å¤„ç†å‡å°‘LLMè°ƒç”¨æ¬¡æ•°
    """
    # æ”¶é›†æ‰€æœ‰éœ€è¦ç²¾ç®€çš„å†…å®¹
    items_to_process = []
    for item in data_list:
        if "name" not in item or "resulte" not in item or "value" not in item:
            continue
        items_to_process.append(item)
    
    if not items_to_process:
        return ""
    
    # ä½¿ç”¨æ‰¹é‡ç²¾ç®€åŠŸèƒ½ï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰é¡¹ç›®
    import time
    start_time = time.time()
    logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡ç²¾ç®€ {len(items_to_process)} ä¸ªæµ‹è¯„é¡¹ç›®")
    simplified_values = simplify_survey_values_batch(items_to_process)
    end_time = time.time()
    logger.info(f"â±ï¸ æ‰¹é‡ç²¾ç®€è€—æ—¶: {end_time - start_time:.2f}ç§’")
    
    # æ„å»ºè¾“å‡ºç»“æœ
    detail_lines = []
    for i, item in enumerate(items_to_process):
        name = item["name"]
        resulte = item["resulte"]
        
        # è·å–å¯¹åº”çš„ç²¾ç®€åå†…å®¹
        if i < len(simplified_values):
            value = simplified_values[i]
        else:
            # å¦‚æœæ‰¹é‡å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°å•ä¸ªå¤„ç†
            logger.warning(f"âš ï¸ æ‰¹é‡å¤„ç†ç»“æœä¸è¶³ï¼Œå›é€€åˆ°å•ä¸ªå¤„ç†é¡¹ç›® {i+1}")
            value = simplify_survey_value(item["value"].replace('\r\n', '\n'))
        
        # æ„å»ºè¾“å‡ºè¡Œ
        detail_line = f"{name}: {resulte}\n{value}"
        detail_lines.append(detail_line)
    
    logger.info(f"âœ… æ‰¹é‡ç²¾ç®€å®Œæˆï¼Œå¤„ç†äº† {len(detail_lines)} ä¸ªæµ‹è¯„é¡¹ç›®")
    return "\n\n".join(detail_lines)


def simplify_survey_value_with_llm(value: str) -> str:
    """
    ä½¿ç”¨LLMç²¾ç®€æµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼Œæå–æ ¸å¿ƒä¿¡æ¯
    ç›´æ¥ä½¿ç”¨ç¡¬ç¼–ç çš„LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒç¼“å­˜
    """
    # æ£€æŸ¥ç¼“å­˜
    import hashlib
    value_hash = hashlib.md5(value.encode('utf-8')).hexdigest()
    if value_hash in _simplify_cache:
        logger.debug("ğŸ”„ ä½¿ç”¨ç¼“å­˜çš„LLMç²¾ç®€ç»“æœ")
        return _simplify_cache[value_hash]
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMç²¾ç®€åŠŸèƒ½
    if not SIMPLIFY_LLM_CONFIG.get("enable_llm_simplify", True):
        logger.info("â„¹ï¸ LLMç²¾ç®€åŠŸèƒ½å·²ç¦ç”¨ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•")
        result = simplify_survey_value_regex(value)
        _simplify_cache[value_hash] = result
        return result
    
    # ç›´æ¥ä½¿ç”¨ç‹¬ç«‹çš„LLMå®¢æˆ·ç«¯
    simplify_client = get_simplify_llm_client()
    if not simplify_client:
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•
        if SIMPLIFY_LLM_CONFIG.get("fallback_to_regex", True):
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•")
            result = simplify_survey_value_regex(value)
            _simplify_cache[value_hash] = result
            return result
        else:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯ä¸”æœªå¯ç”¨æ­£åˆ™è¡¨è¾¾å¼å›é€€")
            _simplify_cache[value_hash] = value
            return value
    
    try:
        # æ„å»ºLLMæç¤ºè¯
        user_prompt_template = SIMPLIFY_LLM_CONFIG.get("user_prompt_template", "")
        if user_prompt_template:
            prompt = user_prompt_template.format(value=value)
        else:
            # ä½¿ç”¨é»˜è®¤æç¤ºè¯
            prompt = f"""è¯·ç²¾ç®€ä»¥ä¸‹æµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼Œåªä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼š

è¦æ±‚ï¼š
1. ç§»é™¤å¼€å¤´çš„å†—ä½™æè¿°"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œå°†å­¦ç”Ÿåˆ’åˆ†ä¸ºå¥åº·ï¼ˆæ·±è“ï¼‰ã€ä¸€èˆ¬å…³æ³¨ï¼ˆæµ…è“ï¼‰ã€é‡ç‚¹å…³æ³¨ï¼ˆé»„è‰²ï¼‰ä¸‰ç±»ï¼Œ"
2. ä¿ç•™æ ‡å‡†æè¿°ï¼ˆå¥åº·ä¸º...ï¼Œä¸€èˆ¬å…³æ³¨ä¸º...ï¼Œé‡ç‚¹å…³æ³¨ä¸º...ï¼‰
3. ä¿ç•™Aæ¡ï¼ˆå­¦ç”ŸçŠ¶æ€æè¿°ï¼‰
4. å¯¹äºBã€Cã€Dæ¡ï¼Œä»…ä¿ç•™åŒ…å«æ•°å­—åŠå‰åå†…å®¹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œå¦‚ï¼š
   - "ä¼˜äºå­¦æ ¡ç»Ÿä¸€æ ·æœ¬é›†39.9çš„äººç¾¤"
   - "ä¼˜äºä¸­æµ·é«˜ç§‘æ•°æ®æä¾›å•ä½ç»Ÿä¸€æ ·æœ¬ç©ºé—´27.6çš„äººç¾¤" 
   - "åŠ£äºå…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡7.1"
   - "è¯¥å­¦ç”ŸåŒä¼´å…³ç³»å¾—åˆ†ä¸º85åˆ†"
   - "è¯¥å­¦ç”ŸæŠ‘éƒæƒ…å†µç­‰äºå…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡"
5. ç§»é™¤æ‰€æœ‰å†—ä½™çš„æè¿°æ€§æ–‡å­—
6. ä¿æŒåŸæœ‰çš„A.ã€B.ã€C.ã€D.å‰ç¼€æ ¼å¼
7. æ— æ•°å­—çš„Bã€Cã€Dæ¡ç›´æ¥è·³è¿‡

åŸå§‹å†…å®¹ï¼š
{value}

ç²¾ç®€åçš„å†…å®¹ï¼š"""

        # è°ƒç”¨LLMè¿›è¡Œç²¾ç®€
        response = simplify_client.chat.completions.create(
            model=SIMPLIFY_LLM_CONFIG["model"],
            messages=[
                {"role": "system", "content": SIMPLIFY_LLM_CONFIG.get("system_prompt", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†æµ‹è¯„æŠ¥å‘Šå¤„ç†åŠ©æ‰‹ï¼Œæ“…é•¿ç²¾ç®€å’Œæå–æ ¸å¿ƒä¿¡æ¯ã€‚")},
                {"role": "user", "content": prompt}
            ],
            temperature=SIMPLIFY_LLM_CONFIG["temperature"],
            max_tokens=SIMPLIFY_LLM_CONFIG["max_tokens"]
        )
        
        # æå–ç²¾ç®€åçš„å†…å®¹
        simplified_content = response.choices[0].message.content.strip()
        logger.info(f"âœ… LLMç²¾ç®€å®Œæˆï¼ŒåŸé•¿åº¦: {len(value)}, ç²¾ç®€åé•¿åº¦: {len(simplified_content)}")
        # ç¼“å­˜ç»“æœ
        _simplify_cache[value_hash] = simplified_content
        return simplified_content
        
    except Exception as e:
        logger.warning(f"âš ï¸ LLMç²¾ç®€å¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•: {e}")
        if SIMPLIFY_LLM_CONFIG.get("fallback_to_regex", True):
            result = simplify_survey_value_regex(value)
            _simplify_cache[value_hash] = result
            return result
        else:
            _simplify_cache[value_hash] = value
            return value


def simplify_survey_value_regex(value: str) -> str:
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç®€æµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
    """
    # 1. ä¿ç•™å¼€å¤´çš„åˆ†ç±»è¯´æ˜ï¼Œåªç§»é™¤"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œå°†å­¦ç”Ÿåˆ’åˆ†ä¸º"éƒ¨åˆ†
    classification_pattern = r"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œå°†å­¦ç”Ÿåˆ’åˆ†ä¸º"
    value = re.sub(classification_pattern, "", value)
    
    # 2. ç§»é™¤æ³¨è§£éƒ¨åˆ†ï¼ˆæ³¨ï¼š...ï¼‰
    note_pattern = r"ï¼ˆæ³¨ï¼š.*?ï¼‰"
    value = re.sub(note_pattern, "", value)
    
    # 3. ç§»é™¤"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º*ä¸‰ç±»ï¼Œ"å†…å®¹ï¼ˆä½¿ç”¨é€šé…ç¬¦åŒ¹é…ï¼‰
    classification_short_pattern = r"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º.*?ä¸‰ç±»ï¼Œ"
    value = re.sub(classification_short_pattern, "", value)
    
    # 3.1 ç§»é™¤å•ç‹¬çš„"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º*ä¸‰ç±»"å†…å®¹ï¼ˆä¸åœ¨å¥å­å¼€å¤´çš„æƒ…å†µï¼‰
    classification_standalone_pattern = r"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º.*?ä¸‰ç±»"
    value = re.sub(classification_standalone_pattern, "", value)
    
    # 4. ç§»é™¤"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹*ç›¸æ¯”è¾ƒ"å†…éƒ¨å†…å®¹ï¼ˆä½¿ç”¨é€šé…ç¬¦åŒ¹é…ï¼‰
    school_test_pattern = r"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹.*?ç›¸æ¯”è¾ƒ,"
    value = re.sub(school_test_pattern, "", value)
    
    # 5. ç§»é™¤"åœ¨æµ‹è¯„ç»“æœçš„å¯¹æ¯”ä¸Š"ç­‰Dæ¡å‰ç¼€
    d_prefix_patterns = [
        r"åœ¨æµ‹è¯„ç»“æœçš„å¯¹æ¯”ä¸Š,ç”±äº[^,]*?,å› æ­¤æ˜¾ç¤ºä¸ºè¯¥å­¦ç”Ÿçš„åˆ†æ•°,",
        r"å…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡ç›¸æ¯”è¾ƒ,",
    ]
    for pattern in d_prefix_patterns:
        value = re.sub(pattern, "", value)
    
    # 6. ç§»é™¤æ‰€æœ‰"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœ"å†…å®¹
    school_result_pattern = r"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœ"
    value = re.sub(school_result_pattern, "", value)
    
    # 7. å¤„ç†Bã€Cã€Dæ¡ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä¿ç•™æ•°å­—æ‰€åœ¨çš„å®Œæ•´é¡¹ç›®
    value = simplify_bcd_items(value)
    
    # 8. æ¸…ç†å¤šä½™çš„ç©ºè¡Œå’Œæ¢è¡Œç¬¦
    value = re.sub(r'\n\s*\n', '\n', value)  # ç§»é™¤å¤šä½™ç©ºè¡Œ
    value = value.strip()  # ç§»é™¤é¦–å°¾ç©ºç™½
    
    return value


def simplify_survey_value(value: str) -> str:
    """
    ç²¾ç®€æµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨LLMï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼
    """
    # ç›´æ¥ä½¿ç”¨LLMç²¾ç®€åŠŸèƒ½
    return simplify_survey_value_with_llm(value)


def simplify_survey_values_batch(items_to_process: list) -> list:
    """
    æ‰¹é‡ç²¾ç®€å¤šä¸ªæµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼Œå‡å°‘LLMè°ƒç”¨æ¬¡æ•°
    è¿”å›ç²¾ç®€åçš„å†…å®¹åˆ—è¡¨ï¼Œé¡ºåºä¸è¾“å…¥ä¸€è‡´
    """
    if not items_to_process:
        return []
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªé¡¹ç›®ï¼Œç›´æ¥å¤„ç†
    if len(items_to_process) == 1:
        item = items_to_process[0]
        value = item["value"].replace('\r\n', '\n')
        simplified_value = simplify_survey_value_with_llm(value)
        return [simplified_value]
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMç²¾ç®€åŠŸèƒ½
    if not SIMPLIFY_LLM_CONFIG.get("enable_llm_simplify", True):
        logger.info("â„¹ï¸ LLMç²¾ç®€åŠŸèƒ½å·²ç¦ç”¨ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•")
        return [simplify_survey_value_regex(item["value"].replace('\r\n', '\n')) for item in items_to_process]
    
    # è·å–LLMå®¢æˆ·ç«¯
    simplify_client = get_simplify_llm_client()
    if not simplify_client:
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•
        if SIMPLIFY_LLM_CONFIG.get("fallback_to_regex", True):
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•")
            return [simplify_survey_value_regex(item["value"].replace('\r\n', '\n')) for item in items_to_process]
        else:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„LLMå®¢æˆ·ç«¯ä¸”æœªå¯ç”¨æ­£åˆ™è¡¨è¾¾å¼å›é€€")
            return [item["value"].replace('\r\n', '\n') for item in items_to_process]
    
    # æ„å»ºæ‰¹é‡å¤„ç†çš„æç¤ºè¯
    batch_content = []
    for i, item in enumerate(items_to_process):
        name = item["name"]
        value = item["value"].replace('\r\n', '\n')
        batch_content.append(f"ã€é¡¹ç›®{i+1}ã€‘{name}:\n{value}")
    
    combined_content = "\n\n".join(batch_content)
    
    # æ£€æŸ¥ç¼“å­˜
    import hashlib
    content_hash = hashlib.md5(combined_content.encode('utf-8')).hexdigest()
    cache_key = f"batch_{content_hash}"
    if cache_key in _simplify_cache:
        logger.debug("ğŸ”„ ä½¿ç”¨ç¼“å­˜çš„æ‰¹é‡LLMç²¾ç®€ç»“æœ")
        return _simplify_cache[cache_key]
    
    try:
        # æ„å»ºLLMæç¤ºè¯
        user_prompt_template = SIMPLIFY_LLM_CONFIG.get("user_prompt_template", "")
        if user_prompt_template:
            prompt = user_prompt_template.format(value=combined_content)
        else:
            # ä½¿ç”¨é»˜è®¤æç¤ºè¯
            prompt = f"""è¯·ç²¾ç®€ä»¥ä¸‹å¤šä¸ªæµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼Œåªä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼š

è¦æ±‚ï¼š
1. ç§»é™¤å¼€å¤´çš„å†—ä½™æè¿°"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œå°†å­¦ç”Ÿåˆ’åˆ†ä¸ºå¥åº·ï¼ˆæ·±è“ï¼‰ã€ä¸€èˆ¬å…³æ³¨ï¼ˆæµ…è“ï¼‰ã€é‡ç‚¹å…³æ³¨ï¼ˆé»„è‰²ï¼‰ä¸‰ç±»ï¼Œ"
2. ä¿ç•™æ ‡å‡†æè¿°ï¼ˆå¥åº·ä¸º...ï¼Œä¸€èˆ¬å…³æ³¨ä¸º...ï¼Œé‡ç‚¹å…³æ³¨ä¸º...ï¼‰
3. ä¿ç•™Aæ¡ï¼ˆå­¦ç”ŸçŠ¶æ€æè¿°ï¼‰
4. å¯¹äºBã€Cã€Dæ¡ï¼Œä»…ä¿ç•™åŒ…å«æ•°å­—åŠå‰åå†…å®¹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œå¦‚ï¼š
   - "ä¼˜äºå­¦æ ¡ç»Ÿä¸€æ ·æœ¬é›†39.9çš„äººç¾¤"
   - "ä¼˜äºä¸­æµ·é«˜ç§‘æ•°æ®æä¾›å•ä½ç»Ÿä¸€æ ·æœ¬ç©ºé—´27.6çš„äººç¾¤" 
   - "åŠ£äºå…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡7.1"
   - "è¯¥å­¦ç”ŸåŒä¼´å…³ç³»å¾—åˆ†ä¸º85åˆ†"
   - "è¯¥å­¦ç”ŸæŠ‘éƒæƒ…å†µç­‰äºå…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡"
5. ç§»é™¤æ‰€æœ‰å†—ä½™çš„æè¿°æ€§æ–‡å­—
6. ä¿æŒåŸæœ‰çš„A.ã€B.ã€C.ã€D.å‰ç¼€æ ¼å¼
7. æ— æ•°å­—çš„Bã€Cã€Dæ¡ç›´æ¥è·³è¿‡

**é‡è¦ï¼šè¯·æŒ‰ç…§ã€é¡¹ç›®1ã€‘ã€ã€é¡¹ç›®2ã€‘ç­‰æ ¼å¼åˆ†åˆ«å¤„ç†æ¯ä¸ªé¡¹ç›®ï¼Œå¹¶åœ¨æ¯ä¸ªé¡¹ç›®ä¹‹é—´ç”¨ã€é¡¹ç›®åˆ†éš”ç¬¦ã€‘åˆ†éš”ã€‚**

åŸå§‹å†…å®¹ï¼š
{combined_content}

ç²¾ç®€åçš„å†…å®¹ï¼š"""

        # è°ƒç”¨LLMè¿›è¡Œæ‰¹é‡ç²¾ç®€
        response = simplify_client.chat.completions.create(
            model=SIMPLIFY_LLM_CONFIG["model"],
            messages=[
                {"role": "system", "content": SIMPLIFY_LLM_CONFIG.get("system_prompt", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†æµ‹è¯„æŠ¥å‘Šå¤„ç†åŠ©æ‰‹ï¼Œæ“…é•¿ç²¾ç®€å’Œæå–æ ¸å¿ƒä¿¡æ¯ã€‚")},
                {"role": "user", "content": prompt}
            ],
            temperature=SIMPLIFY_LLM_CONFIG["temperature"],
            max_tokens=SIMPLIFY_LLM_CONFIG["max_tokens"]
        )
        
        # æå–ç²¾ç®€åçš„å†…å®¹
        simplified_content = response.choices[0].message.content.strip()
        logger.info(f"âœ… æ‰¹é‡LLMç²¾ç®€å®Œæˆï¼ŒåŸé•¿åº¦: {len(combined_content)}, ç²¾ç®€åé•¿åº¦: {len(simplified_content)}")
        
        # æŒ‰é¡¹ç›®åˆ†éš”ç¬¦åˆ†å‰²ç»“æœ
        if "ã€é¡¹ç›®åˆ†éš”ç¬¦ã€‘" in simplified_content:
            results = simplified_content.split("ã€é¡¹ç›®åˆ†éš”ç¬¦ã€‘")
        else:
            # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œå°è¯•æŒ‰é¡¹ç›®ç¼–å·åˆ†å‰²
            import re
            project_pattern = r'ã€é¡¹ç›®\d+ã€‘'
            results = re.split(project_pattern, simplified_content)
            results = [r.strip() for r in results if r.strip()]
        
        # ç¡®ä¿ç»“æœæ•°é‡ä¸è¾“å…¥ä¸€è‡´
        if len(results) != len(items_to_process):
            logger.warning(f"âš ï¸ æ‰¹é‡ç²¾ç®€ç»“æœæ•°é‡ä¸åŒ¹é…ï¼ŒæœŸæœ›{len(items_to_process)}ä¸ªï¼Œå®é™…{len(results)}ä¸ª")
            # å¦‚æœæ•°é‡ä¸åŒ¹é…ï¼Œå›é€€åˆ°é€ä¸ªå¤„ç†
            return [simplify_survey_value_with_llm(item["value"].replace('\r\n', '\n')) for item in items_to_process]
        
        # ç¼“å­˜ç»“æœ
        _simplify_cache[cache_key] = results
        return results
        
    except Exception as e:
        logger.warning(f"âš ï¸ æ‰¹é‡LLMç²¾ç®€å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªå¤„ç†: {e}")
        if SIMPLIFY_LLM_CONFIG.get("fallback_to_regex", True):
            return [simplify_survey_value_regex(item["value"].replace('\r\n', '\n')) for item in items_to_process]
        else:
            return [item["value"].replace('\r\n', '\n') for item in items_to_process]


def simplify_bcd_items(value: str) -> str:
    """
    ç®€åŒ–Bã€Cã€Dæ¡å†…å®¹ï¼Œä»…ä¿ç•™åŒ…å«æ•°å­—çš„æ ¸å¿ƒéƒ¨åˆ†
    æ— æ•°å­—çš„Bã€Cã€Dæ¡ç›´æ¥è·³è¿‡
    """
    # å…ˆå¤„ç†è¡Œå†…çš„Bã€Cã€Dé¡¹
    # ç§»é™¤Bæ¡æ— æ•°å­—å†…å®¹ï¼ˆå¦‚"B.ç¤¾ä¼šç”¨æˆ·æš‚æ— å­¦æ ¡å¯¹æ¯”ã€‚"ï¼‰
    b_no_number_pattern = r'B\.ç¤¾ä¼šç”¨æˆ·æš‚æ— å­¦æ ¡å¯¹æ¯”ã€‚'
    value = re.sub(b_no_number_pattern, '', value)
    
    lines = value.split('\n')
    result_lines = []
    
    for line in lines:
        # æ£€æŸ¥æ˜¯å¦æ˜¯Bã€Cæˆ–Dé¡¹
        if re.match(r'^[BCD]\.', line.strip()):
            # æå–åŒ…å«æ•°å­—çš„æ ¸å¿ƒå†…å®¹
            number_content = extract_number_item(line)
            if number_content:
                # ä¿æŒåŸæœ‰çš„B.ã€C.æˆ–D.å‰ç¼€
                prefix = re.match(r'^[BCD]\.', line.strip()).group()
                result_lines.append(f"{prefix} {number_content}")
            # æ— æ•°å­—çš„Bã€Cã€Dæ¡ç›´æ¥è·³è¿‡
        else:
            result_lines.append(line)
    
    return '\n'.join(result_lines)


def extract_number_item(text: str) -> str:
    """
    æå–BCDé¡¹ç›®ä¸­åŒ…å«æ•°å­—çš„æ ¸å¿ƒéƒ¨åˆ†
    ä»…ä¿ç•™å¦‚"ä¼˜äºå­¦æ ¡ç»Ÿä¸€æ ·æœ¬é›†39.9çš„äººç¾¤"ã€"è¯¥å­¦ç”ŸåŒä¼´å…³ç³»å¾—åˆ†ä¸º85åˆ†"ç­‰æ ¸å¿ƒå†…å®¹
    """
    # ç§»é™¤B.ã€C.æˆ–D.å‰ç¼€
    text = re.sub(r'^[BCD]\.\s*', '', text.strip())
    
    # å®šä¹‰æ•°å­—æ¨¡å¼ï¼ŒåŒ¹é…æ•°å­—åŠå…¶ç›´æ¥ä¸Šä¸‹æ–‡ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
    number_patterns = [
        # å¾—åˆ†ä¸ºæ¨¡å¼ï¼šå¦‚"è¯¥å­¦ç”ŸåŒä¼´å…³ç³»å¾—åˆ†ä¸º85åˆ†"ã€"è¯¥ç”Ÿæ•°å­—åˆ’é”€çš„å¾—åˆ†ä¸º16åˆ†"
        r'([^ï¼Œ,ã€‚ï¼ï¼Ÿï¼›]*?å¾—åˆ†ä¸º\d+\.?\d*åˆ†[^ï¼Œ,ã€‚ï¼ï¼Ÿï¼›]*)',
        # ä¼˜äº+æ•°å­—æ¨¡å¼ï¼šå¦‚"ä¼˜äºå­¦æ ¡ç»Ÿä¸€æ ·æœ¬é›†39.9çš„äººç¾¤"ã€"ä¼˜äºä¸­æµ·é«˜ç§‘æ•°æ®æä¾›å•ä½ç»Ÿä¸€æ ·æœ¬ç©ºé—´27.6çš„äººç¾¤"
        r'(ä¼˜äº[^ï¼Œ,ã€‚ï¼ï¼Ÿï¼›]*?\d+\.?\d*[%åˆ†]?[^ï¼Œ,ã€‚ï¼ï¼Ÿï¼›]*)',
        # åŠ£äº+æ•°å­—æ¨¡å¼ï¼šå¦‚"åŠ£äºå…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡7.1"
        r'(åŠ£äº[^ï¼Œ,ã€‚ï¼ï¼Ÿï¼›]*?\d+\.?\d*[%åˆ†]?[^ï¼Œ,ã€‚ï¼ï¼Ÿï¼›]*)',
        # ç™¾åˆ†æ¯”+äººç¾¤æ¨¡å¼ï¼šå¦‚"39.9%çš„äººç¾¤"ã€"27.6%çš„äººç¾¤"
        r'(\d+\.?\d*%çš„äººç¾¤)',
        # ç™¾åˆ†æ¯”+å¸¸æ¨¡æ¨¡å¼ï¼šå¦‚"48.6%çš„å¸¸æ¨¡"
        r'(\d+\.?\d*%çš„å¸¸æ¨¡)',
        # ç™¾åˆ†æ¯”+æ ·æœ¬ç©ºé—´æ¨¡å¼ï¼šå¦‚"87.8%çš„æ ·æœ¬ç©ºé—´"
        r'(\d+\.?\d*%çš„æ ·æœ¬ç©ºé—´)',
    ]
    
    # æŒ‰ä¼˜å…ˆçº§åŒ¹é…ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ¨¡å¼å°±è¿”å›
    for pattern in number_patterns:
        matches = re.findall(pattern, text)
        if matches:
            # å»é‡å¹¶ä¿æŒé¡ºåº
            unique_matches = []
            seen = set()
            for match in matches:
                match = match.strip()
                if match and match not in seen:
                    unique_matches.append(match)
                    seen.add(match)
            
            if unique_matches:
                # ç”¨é€—å·è¿æ¥å¤šæ¡å¾—åˆ†
                result = 'ï¼Œ'.join(unique_matches)
                # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
                result = re.sub(r'\s+', ' ', result)
                return result
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…æ¨¡å¼ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆè·³è¿‡è¯¥é¡¹ï¼‰
    return ""




def get_guidance_by_dimension(user_id: str, dimension_name: str) -> str:
    """
    æ ¹æ®æµ‹è¯„ç»´åº¦åç§°è·å–å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆ
    å…ˆè·å–ç”¨æˆ·çš„è¯¦ç»†æµ‹è¯„æŠ¥å‘Šï¼Œæ‰¾åˆ°å¯¹åº”ç»´åº¦çš„codeå€¼ï¼Œç„¶åè·å–æŒ‡å¯¼æ–¹æ¡ˆ
    æ”¯æŒLLMç²¾ç®€å†…å®¹
    """
    logger.info(f"ğŸ” æ ¹æ®ç»´åº¦è·å–æŒ‡å¯¼æ–¹æ¡ˆï¼Œç”¨æˆ·ID: {user_id}, ç»´åº¦: {dimension_name}")
    
    # å…ˆè·å–ç”¨æˆ·çš„è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    survey_detail = get_survey_detail(user_id)
    if not survey_detail:
        logger.warning(f"æ— æ³•è·å–ç”¨æˆ· {user_id} çš„æµ‹è¯„æŠ¥å‘Š")
        return ""
    
    # ä»æµ‹è¯„æŠ¥å‘Šä¸­æå–å¯¹åº”ç»´åº¦çš„codeå€¼
    code = extract_code_by_dimension(survey_detail, dimension_name)
    if not code:
        logger.warning(f"æœªæ‰¾åˆ°ç»´åº¦ '{dimension_name}' å¯¹åº”çš„codeå€¼")
        return f"æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°æ‚¨å…³äº'{dimension_name}'çš„æµ‹è¯„ç»“æœï¼Œæ— æ³•æä¾›é’ˆå¯¹æ€§æŒ‡å¯¼ã€‚"
    
    logger.info(f"æ‰¾åˆ°ç»´åº¦ '{dimension_name}' å¯¹åº”çš„codeå€¼: {code}")
    
    # ä½¿ç”¨codeå€¼è·å–æŒ‡å¯¼æ–¹æ¡ˆ
    guidance_plan = get_guidance_plan(code)
    if not guidance_plan:
        logger.warning(f"æ— æ³•è·å–code '{code}' å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆ")
        return f"æŠ±æ­‰ï¼Œæ— æ³•è·å–å…³äº'{dimension_name}'çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚"
    
    logger.info(f"âœ… æˆåŠŸè·å–ç»´åº¦ '{dimension_name}' çš„æŒ‡å¯¼æ–¹æ¡ˆï¼Œå†…å®¹é•¿åº¦: {len(guidance_plan)} å­—ç¬¦")
    return guidance_plan


def extract_code_by_dimension(survey_detail: str, dimension_name: str) -> str:
    """
    ä»è¯¦ç»†æµ‹è¯„æŠ¥å‘Šä¸­æå–æŒ‡å®šç»´åº¦å¯¹åº”çš„codeå€¼
    æ ¼å¼ï¼šç»´åº¦åç§°: codeå€¼\nè¯¦ç»†æµ‹è¯„ä¿¡æ¯
    """
    lines = survey_detail.split('\n')
    
    for i, line in enumerate(lines):
        # æŸ¥æ‰¾åŒ…å«ç»´åº¦åç§°çš„è¡Œ
        if dimension_name in line and ':' in line:
            # æå–codeå€¼ï¼ˆæ ¼å¼ï¼šç»´åº¦åç§°: codeå€¼ï¼‰
            parts = line.split(':')
            if len(parts) >= 2:
                code = parts[1].strip()
                # å¦‚æœcodeå€¼åŒ…å«æ¢è¡Œç¬¦ï¼Œåªå–ç¬¬ä¸€è¡Œï¼ˆå³codeå€¼æœ¬èº«ï¼‰
                if '\n' in code:
                    code = code.split('\n')[0].strip()
                # éªŒè¯codeæ ¼å¼ï¼ˆå¦‚ 1-1-A, 1-2-A, 1-5-Cç­‰ï¼‰
                if '-' in code and len(code) >= 5:
                    logger.info(f"ä»æµ‹è¯„æŠ¥å‘Šä¸­æå–åˆ°codeå€¼: {code}")
                    return code
    
    # å¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
    dimension_mapping = {
        'å­¦ä¹ ç„¦è™‘': 'å­¦ä¹ ç„¦è™‘',
        'çŠ¶æ€ç„¦è™‘': 'çŠ¶æ€ç„¦è™‘', 
        'æŠ‘éƒ': 'æŠ‘éƒ',
        'åŒä¼´å…³ç³»': 'åŒä¼´å…³ç³»',
        'å¸ˆç”Ÿå…³ç³»': 'å¸ˆç”Ÿå…³ç³»',
        'äº²å­å…³ç³»': 'äº²å­å…³ç³»',
        'è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ': 'è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ',
        'è®¡ç®—èƒ½åŠ›': 'è®¡ç®—èƒ½åŠ›',
        'æ³¨æ„èƒ½åŠ›': 'æ³¨æ„èƒ½åŠ›',
        'è¯†å­—èƒ½åŠ›': 'è¯†å­—èƒ½åŠ›',
        'æµç•…èƒ½åŠ›': 'æµç•…èƒ½åŠ›'
    }
    
    # å°è¯•æ¨¡ç³ŠåŒ¹é…
    for key, value in dimension_mapping.items():
        if key in dimension_name or dimension_name in key:
            for line in lines:
                if value in line and ':' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        code = parts[1].strip()
                        # å¦‚æœcodeå€¼åŒ…å«æ¢è¡Œç¬¦ï¼Œåªå–ç¬¬ä¸€è¡Œï¼ˆå³codeå€¼æœ¬èº«ï¼‰
                        if '\n' in code:
                            code = code.split('\n')[0].strip()
                        if '-' in code and len(code) >= 5:
                            logger.info(f"é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°codeå€¼: {code}")
                            return code
    
    logger.warning(f"æœªæ‰¾åˆ°ç»´åº¦ '{dimension_name}' å¯¹åº”çš„codeå€¼")
    return ""


# æ¨¡å—åŠ è½½æ—¶è‡ªåŠ¨åŠ è½½é…ç½®æ–‡ä»¶
load_simplify_llm_config()