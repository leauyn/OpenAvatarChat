import requests
import json
import redis
import re
from loguru import logger

# å…¨å±€ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
_survey_data_cache = {}
_user_info_cache = {}

# Redis è¿æ¥é…ç½®
REDIS_HOST = 'localhost'
REDIS_PORT = 6779
REDIS_DB = 0

def get_redis_connection():
    """è·å– Redis è¿æ¥ï¼Œç¡®ä¿ä»¥æ–‡æœ¬æ ¼å¼å­˜å‚¨"""
    try:
        r = redis.Redis(
            host=REDIS_HOST, 
            port=REDIS_PORT, 
            db=REDIS_DB, 
            decode_responses=True,  # ç¡®ä¿è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—èŠ‚
            encoding='utf-8'        # æ˜ç¡®æŒ‡å®šç¼–ç 
        )
        # æµ‹è¯•è¿æ¥
        r.ping()
        return r
    except Exception as e:
        logger.error(f"Redis è¿æ¥å¤±è´¥: {e}")
        return None

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_user_info",
            "description": "å½“ä½ æƒ³æŸ¥è¯¢æŒ‡å®šç”¨æˆ·çš„ä¸ªäººä¿¡æ¯æ—¶éå¸¸æœ‰ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "åŸºæœ¬ä¿¡æ¯ï¼Œæ¯”å¦‚å§“åã€æ€§åˆ«ã€å¹´é¾„ã€åœ°å€ã€å­¦æ ¡ç­‰ã€‚",
                    }
                },
                "required": ["user_id"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_user_survey_data",
            "description": "å½“ä½ æƒ³æŸ¥è¯¢æŒ‡å®šç”¨æˆ·çš„æµ‹è¯„æ•°æ®ã€æŠ¥å‘Šã€æˆ–ç»“æœæ—¶éå¸¸æœ‰ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "æµ‹è¯„æ•°æ®ï¼Œæ¯”å¦‚é‡ç‚¹å…³æ³¨ã€ä¸€èˆ¬å…³æ³¨ã€å¥åº·ç­‰ã€‚",
                    }
                },
                "required": ["user_id"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "query_knowledge_base",
            "description": "å½“ç”¨æˆ·è¯¢é—®ä»»ä½•å¿ƒç†å¥åº·ã€å¿ƒç†ç†è®ºã€å¿ƒç†å’¨è¯¢ã€å¿ƒç†ç–¾ç—…ã€å¿ƒç†ç—‡çŠ¶ã€å¿ƒç†æµ‹è¯„ã€å¿ƒç†æ²»ç–—æ–¹æ³•ã€å¿ƒç†å¹²é¢„ç­‰ç›¸å…³é—®é¢˜æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ­¤å·¥å…·æŸ¥è¯¢ä¸“ä¸šçŸ¥è¯†åº“è·å–æƒå¨ç­”æ¡ˆã€‚è¿™æ˜¯è·å–ä¸“ä¸šå¿ƒç†çŸ¥è¯†çš„å”¯ä¸€é€”å¾„ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "è¦æŸ¥è¯¢çš„å¿ƒç†å¥åº·ç›¸å…³é—®é¢˜ï¼Œå¦‚å¿ƒç†ç†è®ºã€å’¨è¯¢æ–¹æ³•ã€æµ‹è¯„çŸ¥è¯†ç­‰ã€‚",
                    }
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_guidance_plan",
            "description": "æ ¹æ®æµ‹è¯„ç»“æœçš„codeå€¼æŸ¥è¯¢å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚å½“ç”¨æˆ·éœ€è¦è·å–å…·ä½“çš„å¿ƒç†æŒ‡å¯¼å»ºè®®æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "æµ‹è¯„ç»“æœçš„codeå€¼ï¼Œå¦‚'1-5-C'ï¼Œç”¨äºæŸ¥è¯¢å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚",
                    }
                },
                "required": ["code"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_guidance_by_dimension",
            "description": "æ ¹æ®æµ‹è¯„ç»´åº¦åç§°è·å–å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚å½“ç”¨æˆ·è¯¢é—®å…·ä½“æµ‹è¯„ç»´åº¦çš„è§£å†³æ–¹æ¡ˆæˆ–æŒ‡å¯¼æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ç”¨æˆ·IDï¼Œç”¨äºè·å–è¯¥ç”¨æˆ·çš„æµ‹è¯„ç»“æœã€‚",
                    },
                    "dimension_name": {
                        "type": "string",
                        "description": "æµ‹è¯„ç»´åº¦åç§°ï¼Œå¦‚'å¸ˆç”Ÿå…³ç³»'ã€'åŒä¼´å…³ç³»'ã€'å­¦ä¹ ç„¦è™‘'ã€'æŠ‘éƒ'ã€'è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ'ç­‰ã€‚",
                    }
                },
                "required": ["user_id", "dimension_name"],
            },
        },
    },
]

def parse_survey_data(data_list: list) -> str:
    """
    è§£ææµ‹è¯„æ•°æ®ï¼ŒæŒ‰ç¾¤ä½“åˆ†ç±»ç»„ç»‡æ•°æ®
    è¾“å‡ºæ ¼å¼ï¼šé‡ç‚¹å…³æ³¨: é¡¹ç›®1, é¡¹ç›®2; ä¸€èˆ¬å…³æ³¨: é¡¹ç›®3, é¡¹ç›®4; å¥åº·: é¡¹ç›®5, é¡¹ç›®6
    è‡ªåŠ¨å»é‡ï¼Œæ¯ä¸ªæµ‹è¯„é¡¹ç›®åªä¿ç•™ä¸€ä¸ªç»“æœ
    """
    # æŒ‰ç¾¤ä½“åˆ†ç±»å­˜å‚¨æ•°æ®ï¼Œä½¿ç”¨é›†åˆå»é‡
    group_categories = {
        "é‡ç‚¹å…³æ³¨": set(),
        "ä¸€èˆ¬å…³æ³¨": set(),
        "å¥åº·": set()
    }
    
    for item in data_list:
        if "name" not in item or "value" not in item:
            continue
            
        name = item["name"]
        value = item["value"]
        
        # æå–ç¾¤ä½“ä¿¡æ¯ï¼šæŸ¥æ‰¾ "A." å’Œ "B." ä¹‹é—´çš„ç¾¤ä½“ä¿¡æ¯
        import re
        pattern = r'A\.\s*æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œè¯¥å­¦ç”Ÿ.*?æƒ…å†µï¼Œå¤„äº(.*?)ç¾¤ä½“'
        match = re.search(pattern, value)
        
        if match:
            group_info = match.group(1).strip()
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            pattern2 = r'å¤„äº(.*?)ç¾¤ä½“'
            match2 = re.search(pattern2, value)
            if match2:
                group_info = match2.group(1).strip()
            else:
                # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè·³è¿‡è¯¥é¡¹ç›®
                continue
        
        # æ ¹æ®ç¾¤ä½“ä¿¡æ¯åˆ†ç±»
        if group_info == "é‡ç‚¹å…³æ³¨":
            group_categories["é‡ç‚¹å…³æ³¨"].add(name)
        elif group_info == "ä¸€èˆ¬å…³æ³¨":
            group_categories["ä¸€èˆ¬å…³æ³¨"].add(name)
        elif group_info == "å¥åº·":
            group_categories["å¥åº·"].add(name)
    
    # æ„å»ºè¾“å‡ºå­—ç¬¦ä¸²
    result_lines = []
    for category, items in group_categories.items():
        if items:  # åªæ·»åŠ éç©ºçš„åˆ†ç±»
            # å°†é›†åˆè½¬æ¢ä¸ºæ’åºçš„åˆ—è¡¨ï¼Œç¡®ä¿è¾“å‡ºé¡ºåºä¸€è‡´
            sorted_items = sorted(list(items))
            result_lines.append(f"{category}: {', '.join(sorted_items)}")
    
    return "\n".join(result_lines)


def parse_user_info(user_data: dict) -> str:
    """
    è§£æç”¨æˆ·ä¿¡æ¯ï¼Œæå–æŒ‡å®šå­—æ®µ
    åŒ…å«ï¼šå§“å(name), å¹´çº§(nj)ï¼Œç­çº§(bj)ï¼Œåœ°å€(addressCode)ï¼Œæ€§åˆ«ï¼ˆsex)ï¼Œ å­¦æ ¡åç§°ï¼ˆschoolNameï¼‰
    å¦‚ä¸º null åˆ™ä¸è§£æ
    """
    user_info_lines = []
    
    # å®šä¹‰å­—æ®µæ˜ å°„
    field_mapping = {
        'name': 'å§“å',
        'nj': 'å¹´çº§', 
        'bj': 'ç­çº§',
        'addressCode': 'åœ°å€',
        'sex': 'æ€§åˆ«',
        'schoolName': 'å­¦æ ¡åç§°'
    }
    
    # æ€§åˆ«æ˜ å°„
    sex_mapping = {'1': 'ç”·', '2': 'å¥³', '0': 'æœªçŸ¥'}
    
    for field, display_name in field_mapping.items():
        if field in user_data and user_data[field] is not None:
            value = user_data[field]
            # ç‰¹æ®Šå¤„ç†æ€§åˆ«å­—æ®µ
            if field == 'sex' and value in sex_mapping:
                value = sex_mapping[value]
            user_info_lines.append(f"{display_name}: {value}")
    
    return "\n".join(user_info_lines)


def get_user_info(user_id: str) -> str:
    """
    è·å–ç”¨æˆ·ä¿¡æ¯å¹¶è¿”å›è§£æç»“æœ
    ä½¿ç”¨ Redis ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
    """
    # é»˜è®¤API URL
    api_url = "https://www.zhgk-mind.com/api/dwsurvey/anon/response/userInfo.do"
    
    # Redis ç¼“å­˜ key æ ¼å¼: userid:user_info
    redis_key = f"{user_id}:user_info"
    
    # å°è¯•ä» Redis è·å–ç¼“å­˜
    redis_conn = get_redis_connection()
    if redis_conn:
        try:
            cached_data = redis_conn.get(redis_key)
            if cached_data:
                logger.debug(f"Using Redis cached user info for user {user_id}")
                return cached_data
        except Exception as e:
            logger.warning(f"Redis è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
    
    # å¦‚æœ Redis ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜
    cache_key = f"{user_id}_{api_url}"
    if cache_key in _user_info_cache:
        logger.debug(f"Using memory cached user info for user {user_id}")
        return _user_info_cache[cache_key]
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
            'Referer': 'https://www.zhgk-mind.com/'
        }
        
        response = requests.get(f"{api_url}?userId={user_id}", headers=headers, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get("resultCode") == 200 and "data" in result:
            user_data = result["data"]
            parsed_info = parse_user_info(user_data)
            
            # ä¼˜å…ˆå­˜å‚¨åˆ° Redis
            if redis_conn:
                try:
                    redis_conn.set(redis_key, parsed_info, ex=604800)  # è®¾ç½®1å‘¨è¿‡æœŸæ—¶é—´
                    logger.info(f"Cached user info to Redis for user {user_id} (expires in 1 week)")
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
                    # å›é€€åˆ°å†…å­˜ç¼“å­˜
                    _user_info_cache[cache_key] = parsed_info
                    logger.info(f"Cached user info to memory for user {user_id}")
            else:
                # Redis ä¸å¯ç”¨æ—¶ä½¿ç”¨å†…å­˜ç¼“å­˜
                _user_info_cache[cache_key] = parsed_info
                logger.info(f"Cached user info to memory for user {user_id}")
            
            return parsed_info
        else:
            logger.warning(f"Failed to get user info: {result.get('resultMsg', 'Unknown error')}")
            return ""
    except Exception as e:
        logger.error(f"Error fetching user info: {e}")
        return ""


def get_user_survey_data(user_id: str) -> str:
    """
    è·å–ç”¨æˆ·æµ‹è¯„æ•°æ®å¹¶è¿”å›è¯¦ç»†è§£æç»“æœ
    ä½¿ç”¨ get_survey_detail å‡½æ•°è·å–è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    """
    # ç›´æ¥è°ƒç”¨ get_survey_detail å‡½æ•°è·å–è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    return get_survey_detail(user_id)


def query_knowledge_base(query: str, rag_api_url: str = None, rag_api_key: str = None, rag_model: str = None) -> str:
    """
    æŸ¥è¯¢çŸ¥è¯†åº“è·å–ä¸“ä¸šå¿ƒç†çŸ¥è¯†ç­”æ¡ˆ
    è¿”å›å®Œæ•´çš„å›ç­”å†…å®¹ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    # é»˜è®¤RAGé…ç½®
    default_rag_api_url = "https://ragflow.thinnovate.com/api/v1/chats_openai/9a15923a991b11f088f40242ac170006/chat/completions"
    default_rag_api_key = "ragflow-I5ZWIyNDk0OTg3MDExZjBiZWNlMDI0Mm"
    default_rag_model = "model"
    
    # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤å€¼
    api_url = rag_api_url or default_rag_api_url
    api_key = rag_api_key or default_rag_api_key
    model = rag_model or default_rag_model
    
    logger.info(f"ğŸ§  RAGå·¥å…·è°ƒç”¨å¼€å§‹")
    logger.info(f"ğŸ“ æŸ¥è¯¢é—®é¢˜: {query}")
    logger.info(f"ğŸ”— API URL: {api_url}")
    logger.info(f"ğŸ”‘ API Key: {api_key[:20]}...")
    logger.info(f"ğŸ¤– Model: {model}")
    
    try:
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        
        data = {
            "model": model,
            "messages": [{"role": "user", "content": query}],
            "stream": True
        }
        
        logger.info(f"æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œé—®é¢˜: {query[:50]}...")
        response = requests.post(api_url, headers=headers, json=data, timeout=30, stream=True)
        response.raise_for_status()
        
        full_response = ""
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data:'):
                    try:
                        json_data = json.loads(line[5:])  # å»æ‰ 'data:' å‰ç¼€
                        if (json_data.get('choices') and 
                            len(json_data['choices']) > 0 and 
                            json_data['choices'][0].get('delta', {}).get('content') is not None):
                            content = json_data['choices'][0]['delta']['content']
                            if content:  # ç¡®ä¿contentä¸ä¸ºç©ºå­—ç¬¦ä¸²
                                full_response += content
                    except json.JSONDecodeError as e:
                        logger.debug(f"JSONè§£æé”™è¯¯: {e}, åŸå§‹æ•°æ®: {line}")
                        continue
        
        # æ£€æŸ¥æ˜¯å¦è¿”å›äº†"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°æ‚¨è¦çš„ç­”æ¡ˆ"
        if "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°æ‚¨è¦çš„ç­”æ¡ˆ" in full_response:
            logger.warning("âš ï¸ çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ç­”æ¡ˆ")
            return ""
        
        logger.info(f"âœ… çŸ¥è¯†åº“æŸ¥è¯¢æˆåŠŸï¼Œè¿”å›ç­”æ¡ˆé•¿åº¦: {len(full_response)} å­—ç¬¦")
        if full_response:
            logger.info(f"ğŸ“„ çŸ¥è¯†åº“è¿”å›å†…å®¹é¢„è§ˆ: {full_response[:200]}...")
        return full_response
        
    except Exception as e:
        logger.error(f"âŒ çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {e}")
        return ""


def get_guidance_plan(code: str) -> str:
    """
    æ ¹æ®æµ‹è¯„ç»“æœçš„codeå€¼æŸ¥è¯¢å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆ
    ä½¿ç”¨ Redis ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
    """
    # é»˜è®¤API URL
    api_url = "https://www.zhgk-mind.com/api/dwsurvey/anon/response/getBaseMindResult.do"
    
    # Redis ç¼“å­˜ key æ ¼å¼: code:guidance
    redis_key = f"{code}:guidance"
    
    # å°è¯•ä» Redis è·å–ç¼“å­˜
    redis_conn = get_redis_connection()
    if redis_conn:
        try:
            cached_data = redis_conn.get(redis_key)
            if cached_data:
                logger.debug(f"Using Redis cached guidance plan for code {code}")
                return cached_data
        except Exception as e:
            logger.warning(f"Redis è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
    
    # å¦‚æœ Redis ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜
    cache_key = f"{code}_guidance"
    if cache_key in _user_info_cache:  # å¤ç”¨ç°æœ‰çš„ç¼“å­˜å­—å…¸
        logger.debug(f"Using memory cached guidance plan for code {code}")
        return _user_info_cache[cache_key]
    
    try:
        headers = {'content-type': 'application/json'}
        data = {"code": code}
        
        logger.info(f"æŸ¥è¯¢æŒ‡å¯¼æ–¹æ¡ˆï¼Œcode: {code}")
        response = requests.post(api_url, headers=headers, json=data, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get("resultCode") == 200 and "data" in result and result["data"]:
            guidance_data = result["data"][0]  # å–ç¬¬ä¸€ä¸ªç»“æœ
            guidance_text = guidance_data.get("value", "")
            
            # æ¸…ç†æ–‡æœ¬ä¸­çš„ \r\n æ¢è¡Œç¬¦ï¼Œæ›¿æ¢ä¸º \n
            guidance_text = guidance_text.replace('\r\n', '\n')
            
            # ä¼˜å…ˆå­˜å‚¨åˆ° Redis
            if redis_conn:
                try:
                    redis_conn.set(redis_key, guidance_text, ex=604800)  # è®¾ç½®1å‘¨è¿‡æœŸæ—¶é—´
                    logger.info(f"Cached guidance plan to Redis for code {code} (expires in 1 week)")
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
                    # å›é€€åˆ°å†…å­˜ç¼“å­˜
                    _user_info_cache[cache_key] = guidance_text
                    logger.info(f"Cached guidance plan to memory for code {code}")
            else:
                # Redis ä¸å¯ç”¨æ—¶ä½¿ç”¨å†…å­˜ç¼“å­˜
                _user_info_cache[cache_key] = guidance_text
                logger.info(f"Cached guidance plan to memory for code {code}")
            
            logger.info(f"âœ… æŒ‡å¯¼æ–¹æ¡ˆæŸ¥è¯¢æˆåŠŸï¼Œcode: {code}, å†…å®¹é•¿åº¦: {len(guidance_text)} å­—ç¬¦")
            return guidance_text
        else:
            logger.warning(f"Failed to get guidance plan for code {code}: {result.get('resultMsg', 'Unknown error')}")
            return ""
    except Exception as e:
        logger.error(f"Error fetching guidance plan for code {code}: {e}")
        return ""


def get_survey_detail(user_id: str) -> str:
    """
    è·å–ç”¨æˆ·è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    ä»å“åº”åˆ—è¡¨ä¸­æŠ½å–å„ä¸ªæµ‹è¯„ç»´åº¦ä¸­çš„ nameï¼ˆç»´åº¦åç§°ï¼‰ã€resulteï¼ˆæµ‹è¯„ç»“æœ codeï¼‰ä¸ valueå€¼ï¼ˆè¯¦ç»†æµ‹è¯„ä¿¡æ¯ï¼‰
    ä½¿ç”¨ Redis ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
    """
    # é»˜è®¤API URL
    api_url = "https://www.zhgk-mind.com/api/dwsurvey/anon/response/getUserResultInfo.do"
    
    # Redis ç¼“å­˜ key æ ¼å¼: userid:survey_detail
    redis_key = f"{user_id}:survey_detail"
    
    # å°è¯•ä» Redis è·å–ç¼“å­˜
    redis_conn = get_redis_connection()
    if redis_conn:
        try:
            cached_data = redis_conn.get(redis_key)
            if cached_data:
                logger.debug(f"Using Redis cached survey detail for user {user_id}")
                return cached_data
        except Exception as e:
            logger.warning(f"Redis è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
    
    # å¦‚æœ Redis ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜
    cache_key = f"{user_id}_survey_detail"
    if cache_key in _user_info_cache:  # å¤ç”¨ç°æœ‰çš„ç¼“å­˜å­—å…¸
        logger.debug(f"Using memory cached survey detail for user {user_id}")
        return _user_info_cache[cache_key]
    
    try:
        headers = {'content-type': 'application/json'}
        data = {"userId": user_id}
        
        logger.info(f"æŸ¥è¯¢è¯¦ç»†æµ‹è¯„æŠ¥å‘Šï¼Œuser_id: {user_id}")
        response = requests.post(api_url, headers=headers, json=data, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get("resultCode") == 200 and "data" in result:
            data_list = result["data"]
            parsed_detail = parse_survey_detail(data_list)
            
            # ä¼˜å…ˆå­˜å‚¨åˆ° Redis
            if redis_conn:
                try:
                    redis_conn.set(redis_key, parsed_detail, ex=604800)  # è®¾ç½®1å‘¨è¿‡æœŸæ—¶é—´
                    logger.info(f"Cached survey detail to Redis for user {user_id} (expires in 1 week)")
                except Exception as e:
                    logger.warning(f"Redis å†™å…¥å¤±è´¥ï¼Œå›é€€åˆ°å†…å­˜ç¼“å­˜: {e}")
                    # å›é€€åˆ°å†…å­˜ç¼“å­˜
                    _user_info_cache[cache_key] = parsed_detail
                    logger.info(f"Cached survey detail to memory for user {user_id}")
            else:
                # Redis ä¸å¯ç”¨æ—¶ä½¿ç”¨å†…å­˜ç¼“å­˜
                _user_info_cache[cache_key] = parsed_detail
                logger.info(f"Cached survey detail to memory for user {user_id}")
            
            logger.info(f"âœ… è¯¦ç»†æµ‹è¯„æŠ¥å‘ŠæŸ¥è¯¢æˆåŠŸï¼Œuser_id: {user_id}, å†…å®¹é•¿åº¦: {len(parsed_detail)} å­—ç¬¦")
            return parsed_detail
        else:
            logger.warning(f"Failed to get survey detail for user {user_id}: {result.get('resultMsg', 'Unknown error')}")
            return ""
    except Exception as e:
        logger.error(f"Error fetching survey detail for user {user_id}: {e}")
        return ""


def parse_survey_detail(data_list: list) -> str:
    """
    è§£æè¯¦ç»†æµ‹è¯„æ•°æ®ï¼Œæå–å„ä¸ªç»´åº¦çš„ä¿¡æ¯
    è¾“å‡ºæ ¼å¼ï¼šç»´åº¦åç§°: æµ‹è¯„ç»“æœcode - è¯¦ç»†æµ‹è¯„ä¿¡æ¯
    """
    detail_lines = []
    
    for item in data_list:
        if "name" not in item or "resulte" not in item or "value" not in item:
            continue
            
        name = item["name"]
        resulte = item["resulte"]
        value = item["value"]
        
        # æ¸…ç†æ–‡æœ¬ä¸­çš„ \r\n æ¢è¡Œç¬¦ï¼Œæ›¿æ¢ä¸º \n
        value = value.replace('\r\n', '\n')
        
        # ç²¾ç®€å†…å®¹ï¼šç§»é™¤å†—ä½™ä¿¡æ¯
        value = simplify_survey_value(value)
        
        # æ„å»ºè¾“å‡ºè¡Œ
        detail_line = f"{name}: {resulte}\n{value}"
        detail_lines.append(detail_line)
    
    return "\n\n".join(detail_lines)


def simplify_survey_value(value: str) -> str:
    """
    ç²¾ç®€æµ‹è¯„æŠ¥å‘Šå†…å®¹ï¼Œç§»é™¤å†—ä½™ä¿¡æ¯
    """
    # 1. ç§»é™¤å¼€å¤´çš„åˆ†ç±»è¯´æ˜
    classification_pattern = r"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœï¼Œå°†å­¦ç”Ÿåˆ’åˆ†ä¸ºå¥åº·ï¼ˆæ·±è“ï¼‰ã€ä¸€èˆ¬å…³æ³¨ï¼ˆæµ…è“ï¼‰ã€é‡ç‚¹å…³æ³¨ï¼ˆé»„è‰²ï¼‰ä¸‰ç±»ï¼Œ.*?ã€‚\r?\n"
    value = re.sub(classification_pattern, "", value)
    
    # 2. ç§»é™¤æ³¨è§£éƒ¨åˆ†ï¼ˆæ³¨ï¼š...ï¼‰
    note_pattern = r"ï¼ˆæ³¨ï¼š.*?ï¼‰"
    value = re.sub(note_pattern, "", value)
    
    # 3. ç§»é™¤"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º*ä¸‰ç±»ï¼Œ"å†…å®¹ï¼ˆä½¿ç”¨é€šé…ç¬¦åŒ¹é…ï¼‰
    classification_short_pattern = r"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º.*?ä¸‰ç±»ï¼Œ"
    value = re.sub(classification_short_pattern, "", value)
    
    # 3.1 ç§»é™¤å•ç‹¬çš„"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º*ä¸‰ç±»"å†…å®¹ï¼ˆä¸åœ¨å¥å­å¼€å¤´çš„æƒ…å†µï¼‰
    classification_standalone_pattern = r"å°†å­¦ç”Ÿåˆ’åˆ†ä¸º.*?ä¸‰ç±»"
    value = re.sub(classification_standalone_pattern, "", value)
    
    # 4. ç§»é™¤"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹*ç›¸æ¯”è¾ƒ"å†…éƒ¨å†…å®¹ï¼ˆä½¿ç”¨é€šé…ç¬¦åŒ¹é…ï¼‰
    school_test_pattern = r"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹.*?ç›¸æ¯”è¾ƒ,"
    value = re.sub(school_test_pattern, "", value)
    
    # 5. ç§»é™¤"åœ¨æµ‹è¯„ç»“æœçš„å¯¹æ¯”ä¸Š"ç­‰Dæ¡å‰ç¼€
    d_prefix_patterns = [
        r"åœ¨æµ‹è¯„ç»“æœçš„å¯¹æ¯”ä¸Š,ç”±äº[^,]*?,å› æ­¤æ˜¾ç¤ºä¸ºè¯¥å­¦ç”Ÿçš„åˆ†æ•°,",
        r"å…¨å›½å…¶ä»–åœ°åŒºå¸¸æ¨¡ç›¸æ¯”è¾ƒ,",
    ]
    for pattern in d_prefix_patterns:
        value = re.sub(pattern, "", value)
    
    # 6. ç§»é™¤æ‰€æœ‰"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœ"å†…å®¹
    school_result_pattern = r"æ ¹æ®å­¦æ ¡é‡è¡¨æµ‹è¯„ç»“æœ"
    value = re.sub(school_result_pattern, "", value)
    
    # 7. å¤„ç†Bã€Cã€Dæ¡ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä¿ç•™æ•°å­—æ‰€åœ¨çš„å®Œæ•´é¡¹ç›®
    value = simplify_bcd_items(value)
    
    # 8. æ¸…ç†å¤šä½™çš„ç©ºè¡Œå’Œæ¢è¡Œç¬¦
    value = re.sub(r'\n\s*\n', '\n', value)  # ç§»é™¤å¤šä½™ç©ºè¡Œ
    value = value.strip()  # ç§»é™¤é¦–å°¾ç©ºç™½
    
    return value


def simplify_bcd_items(value: str) -> str:
    """
    ç®€åŒ–Bã€Cã€Dæ¡å†…å®¹ï¼ŒæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä¿ç•™æ•°å­—æ‰€åœ¨çš„å®Œæ•´é¡¹ç›®
    æ— æ•°å­—çš„Bã€Cã€Dæ¡ç›´æ¥è·³è¿‡
    """
    # å…ˆå¤„ç†è¡Œå†…çš„Bã€Cã€Dé¡¹
    # ç§»é™¤Bæ¡æ— æ•°å­—å†…å®¹ï¼ˆå¦‚"B.ç¤¾ä¼šç”¨æˆ·æš‚æ— å­¦æ ¡å¯¹æ¯”ã€‚"ï¼‰
    b_no_number_pattern = r'B\.ç¤¾ä¼šç”¨æˆ·æš‚æ— å­¦æ ¡å¯¹æ¯”ã€‚'
    value = re.sub(b_no_number_pattern, '', value)
    
    lines = value.split('\n')
    result_lines = []
    
    for line in lines:
        # æ£€æŸ¥æ˜¯å¦æ˜¯Bã€Cæˆ–Dé¡¹
        if re.match(r'^[BCD]\.', line.strip()):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—
            if has_number(line):
                # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä¿ç•™æ•°å­—æ‰€åœ¨çš„å®Œæ•´é¡¹ç›®
                number_content = extract_number_item(line)
                if number_content:
                    # ä¿æŒåŸæœ‰çš„B.ã€C.æˆ–D.å‰ç¼€
                    prefix = re.match(r'^[BCD]\.', line.strip()).group()
                    result_lines.append(f"{prefix} {number_content}")
                else:
                    # å¦‚æœæå–å¤±è´¥ï¼Œä¿ç•™åŸè¡Œ
                    result_lines.append(line)
            else:
                # æ— æ•°å­—çš„Bã€Cã€Dæ¡ç›´æ¥è·³è¿‡
                continue
        else:
            result_lines.append(line)
    
    return '\n'.join(result_lines)


def has_number(text: str) -> bool:
    """
    æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆåŒ…æ‹¬ç™¾åˆ†æ¯”ã€åˆ†æ•°ç­‰ï¼‰
    """
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆåŒ…æ‹¬ç™¾åˆ†æ¯”ã€åˆ†æ•°ç­‰ï¼‰
    return bool(re.search(r'\d+\.?\d*[%åˆ†]?', text))


def extract_number_item(text: str) -> str:
    """
    æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²Bã€Cã€Dæ¡å†…å®¹ï¼Œä¿ç•™æ•°å­—æ‰€åœ¨çš„å®Œæ•´é¡¹ç›®
    æ”¯æŒå…¨è§’å’ŒåŠè§’é€—å·ä½œä¸ºåˆ†å‰²ç¬¦
    """
    # ç§»é™¤B.ã€C.æˆ–D.å‰ç¼€
    text = re.sub(r'^[BCD]\.\s*', '', text.strip())
    
    # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²æˆé¡¹ç›®åˆ—è¡¨ï¼Œä¿ç•™åˆ†å‰²ç¬¦
    # ä½¿ç”¨å¤šç§æ ‡ç‚¹ç¬¦å·ä½œä¸ºåˆ†å‰²ç¬¦ï¼šã€‚ï¼ï¼Ÿï¼›ï¼Œ,ï¼ˆå…¨è§’å’ŒåŠè§’é€—å·ï¼‰
    items = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œ,])', text)
    
    # é‡æ–°ç»„åˆé¡¹ç›®ï¼Œæ¯ä¸ªé¡¹ç›®åŒ…å«å…¶æ ‡ç‚¹ç¬¦å·
    combined_items = []
    for i in range(0, len(items), 2):
        if i + 1 < len(items):
            item = items[i].strip() + items[i + 1]
            if item.strip():
                combined_items.append(item.strip())
        elif items[i].strip():
            combined_items.append(items[i].strip())
    
    # æŸ¥æ‰¾åŒ…å«æ•°å­—çš„é¡¹ç›®
    for item in combined_items:
        # æ£€æŸ¥é¡¹ç›®æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆåŒ…æ‹¬ç™¾åˆ†æ¯”ã€åˆ†æ•°ç­‰ï¼‰
        if re.search(r'\d+\.?\d*[%åˆ†]?', item):
            return item
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ…å«æ•°å­—çš„é¡¹ç›®ï¼Œè¿”å›åŸæ–‡æœ¬
    return text


def extract_number_content(text: str) -> str:
    """
    æå–å«æœ‰æ•°å­—çš„éƒ¨åˆ†å†…å®¹
    æ ¹æ®å›¾ç‰‡ç¤ºä¾‹ï¼Œæå–ç±»ä¼¼"30.7%çš„äººç¾¤"ã€"27.6%çš„äººç¾¤"ã€"12.2%"è¿™æ ·çš„å†…å®¹
    """
    # ç§»é™¤B.ã€C.æˆ–D.å‰ç¼€
    text = re.sub(r'^[BCD]\.\s*', '', text.strip())
    
    # æŸ¥æ‰¾å«æœ‰æ•°å­—å’Œç™¾åˆ†æ¯”çš„æ¨¡å¼
    # åŒ¹é…æ¨¡å¼ï¼šæ•°å­—% + å¯é€‰çš„äººç¾¤/å¸¸æ¨¡ç­‰è¯æ±‡
    number_patterns = [
        r'(\d+\.?\d*%[^ã€‚ï¼ï¼Ÿï¼›ï¼Œ]*?[äººç¾¤å¸¸æ¨¡æ ·æœ¬ç©ºé—´])',  # æ•°å­—% + äººç¾¤/å¸¸æ¨¡ç­‰
        r'(\d+\.?\d*%[^ã€‚ï¼ï¼Ÿï¼›ï¼Œ]*)',  # æ•°å­—% + å…¶ä»–å†…å®¹
        r'(\d+\.?\d*[^ã€‚ï¼ï¼Ÿï¼›ï¼Œ]*?%)',  # æ•°å­— + å…¶ä»–å†…å®¹ + %
    ]
    
    for pattern in number_patterns:
        matches = re.findall(pattern, text)
        if matches:
            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„å†…å®¹
            result = matches[0].strip()
            # ç¡®ä¿"äººç¾¤"ç­‰è¯æ±‡å®Œæ•´
            if result.endswith('äºº') and 'äººç¾¤' in text:
                result = result + 'ç¾¤'
            return result
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç™¾åˆ†æ¯”ï¼ŒæŸ¥æ‰¾å…¶ä»–æ•°å­—æ¨¡å¼
    simple_number_pattern = r'(\d+\.?\d*[^ã€‚ï¼ï¼Ÿï¼›ï¼Œ]*)'
    matches = re.findall(simple_number_pattern, text)
    if matches:
        return matches[0].strip()
    
    return text


def extract_last_sentence(text: str) -> str:
    """
    æå–æ–‡æœ¬ä¸­çš„æœ€åä¸€å¥è¯ï¼ˆä»¥æ ‡ç‚¹ç¬¦å·ä¸ºåˆ†å‰²ï¼‰
    """
    # ç§»é™¤C.æˆ–D.å‰ç¼€
    text = re.sub(r'^[CD]\.\s*', '', text.strip())
    
    # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²å¥å­ï¼Œä¿ç•™åˆ†éš”ç¬¦
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œ])', text)
    
    # é‡æ–°ç»„åˆå¥å­ï¼Œæ¯ä¸ªå¥å­åŒ…å«å…¶æ ‡ç‚¹ç¬¦å·
    combined_sentences = []
    for i in range(0, len(sentences), 2):
        if i + 1 < len(sentences):
            sentence = sentences[i].strip() + sentences[i + 1]
            if sentence.strip():
                combined_sentences.append(sentence.strip())
        elif sentences[i].strip():
            combined_sentences.append(sentences[i].strip())
    
    # è¿”å›æœ€åä¸€å¥è¯
    if combined_sentences:
        return combined_sentences[-1]
    else:
        return text


def get_guidance_by_dimension(user_id: str, dimension_name: str) -> str:
    """
    æ ¹æ®æµ‹è¯„ç»´åº¦åç§°è·å–å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆ
    å…ˆè·å–ç”¨æˆ·çš„è¯¦ç»†æµ‹è¯„æŠ¥å‘Šï¼Œæ‰¾åˆ°å¯¹åº”ç»´åº¦çš„codeå€¼ï¼Œç„¶åè·å–æŒ‡å¯¼æ–¹æ¡ˆ
    """
    logger.info(f"ğŸ” æ ¹æ®ç»´åº¦è·å–æŒ‡å¯¼æ–¹æ¡ˆï¼Œç”¨æˆ·ID: {user_id}, ç»´åº¦: {dimension_name}")
    
    # å…ˆè·å–ç”¨æˆ·çš„è¯¦ç»†æµ‹è¯„æŠ¥å‘Š
    survey_detail = get_survey_detail(user_id)
    if not survey_detail:
        logger.warning(f"æ— æ³•è·å–ç”¨æˆ· {user_id} çš„æµ‹è¯„æŠ¥å‘Š")
        return ""
    
    # ä»æµ‹è¯„æŠ¥å‘Šä¸­æå–å¯¹åº”ç»´åº¦çš„codeå€¼
    code = extract_code_by_dimension(survey_detail, dimension_name)
    if not code:
        logger.warning(f"æœªæ‰¾åˆ°ç»´åº¦ '{dimension_name}' å¯¹åº”çš„codeå€¼")
        return f"æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°æ‚¨å…³äº'{dimension_name}'çš„æµ‹è¯„ç»“æœï¼Œæ— æ³•æä¾›é’ˆå¯¹æ€§æŒ‡å¯¼ã€‚"
    
    logger.info(f"æ‰¾åˆ°ç»´åº¦ '{dimension_name}' å¯¹åº”çš„codeå€¼: {code}")
    
    # ä½¿ç”¨codeå€¼è·å–æŒ‡å¯¼æ–¹æ¡ˆ
    guidance_plan = get_guidance_plan(code)
    if not guidance_plan:
        logger.warning(f"æ— æ³•è·å–code '{code}' å¯¹åº”çš„æŒ‡å¯¼æ–¹æ¡ˆ")
        return f"æŠ±æ­‰ï¼Œæ— æ³•è·å–å…³äº'{dimension_name}'çš„æŒ‡å¯¼æ–¹æ¡ˆã€‚"
    
    logger.info(f"âœ… æˆåŠŸè·å–ç»´åº¦ '{dimension_name}' çš„æŒ‡å¯¼æ–¹æ¡ˆï¼Œå†…å®¹é•¿åº¦: {len(guidance_plan)} å­—ç¬¦")
    return guidance_plan


def extract_code_by_dimension(survey_detail: str, dimension_name: str) -> str:
    """
    ä»è¯¦ç»†æµ‹è¯„æŠ¥å‘Šä¸­æå–æŒ‡å®šç»´åº¦å¯¹åº”çš„codeå€¼
    """
    lines = survey_detail.split('\n')
    
    for i, line in enumerate(lines):
        # æŸ¥æ‰¾åŒ…å«ç»´åº¦åç§°çš„è¡Œ
        if dimension_name in line and ':' in line:
            # æå–codeå€¼ï¼ˆæ ¼å¼ï¼šç»´åº¦åç§°: codeå€¼ï¼‰
            parts = line.split(':')
            if len(parts) >= 2:
                code = parts[1].strip()
                # éªŒè¯codeæ ¼å¼ï¼ˆå¦‚ 1-5-Cï¼‰
                if '-' in code and len(code) >= 5:
                    logger.info(f"ä»æµ‹è¯„æŠ¥å‘Šä¸­æå–åˆ°codeå€¼: {code}")
                    return code
    
    # å¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
    dimension_mapping = {
        'å­¦ä¹ ç„¦è™‘': 'å­¦ä¹ ç„¦è™‘',
        'çŠ¶æ€ç„¦è™‘': 'çŠ¶æ€ç„¦è™‘', 
        'æŠ‘éƒ': 'æŠ‘éƒ',
        'åŒä¼´å…³ç³»': 'åŒä¼´å…³ç³»',
        'å¸ˆç”Ÿå…³ç³»': 'å¸ˆç”Ÿå…³ç³»',
        'äº²å­å…³ç³»': 'äº²å­å…³ç³»',
        'è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ': 'è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ',
        'è®¡ç®—èƒ½åŠ›': 'è®¡ç®—èƒ½åŠ›',
        'æ³¨æ„èƒ½åŠ›': 'æ³¨æ„èƒ½åŠ›',
        'è¯†å­—èƒ½åŠ›': 'è¯†å­—èƒ½åŠ›',
        'æµç•…èƒ½åŠ›': 'æµç•…èƒ½åŠ›'
    }
    
    # å°è¯•æ¨¡ç³ŠåŒ¹é…
    for key, value in dimension_mapping.items():
        if key in dimension_name or dimension_name in key:
            for line in lines:
                if value in line and ':' in line:
                    parts = line.split(':')
                    if len(parts) >= 2:
                        code = parts[1].strip()
                        if '-' in code and len(code) >= 5:
                            logger.info(f"é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°codeå€¼: {code}")
                            return code
    
    logger.warning(f"æœªæ‰¾åˆ°ç»´åº¦ '{dimension_name}' å¯¹åº”çš„codeå€¼")
    return ""